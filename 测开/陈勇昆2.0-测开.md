# 一、自我介绍

各位面试官好，我是xxx，目前就读于四川大学电子信息学院电子信息专业，我所在的实验室为智能所。在校期间，我始终保持着优异的学习成绩，GPA排名为前5%，并荣获学业奖学金、优秀研究生等荣誉。当前掌握java编程、jvm虚拟机、mysql数据库、linux系统等 java基本开发工具的，以及计算机网络、操作系统、数据结构等相关基础知识。

在项目经历方面，我参与开发了智慧社区综合服务平台，该平台基于 SpringBoot 构建，涵盖智慧党建、社区生活服务、AI 能力管理等多个模块。在项目中，我主要负责：多数据源设计，针对不同数据存放不同的数据库；提高redis缓存命中率，缩短接口响应时间。多线程池配置，通过线程池优化AI处理视频帧任务，支持机器人并发监控。

另一个项目是基于 SpringBoot 的校园外卖服务平台。我参与了后端的开发，采用 JWT 实现用户身份认证，通过 Redis 缓存菜品数据，结合 RabbitMQ 实现消息异步处理，显著提升了系统在高并发下的响应性能。项目中还使用 WebSocket 完成订单状态的实时通知与催单功能，并借助 SpringTask 实现了订单超时的自动处理机制，提升了用户体验和系统稳定性。

在参与实验室项目的过程中，我也会利用根据项目的需求不断地了解和学习新的技术和内容。 
在生活中，我喜欢读书、运动和乒乓球，有较强的学习能力和环境适应能力，并具备良好的团队协作精神

# 二、智慧社区

### 项目背景 

这个是我们导师接的一个项目，主要是和政府合作，成都市为了探索超大城市精细化治理水平做的一个示范项目(清远和同德两个社区)，这个项目由三个实验室负责，一个是AI算法，一个是智能机器人，我们实验室主要负责系统的开发，我们这边也是分为两个部分，一个是数据的处理，在我们这个项目里面数据来源多种多样，有离线数据，实时数据等，离线数据包含一些社区网格信息，社区居民信息，街景视频等。实时数据就包含一些视频监控，传感器数据，交通数据等。数据的处理就包括数据集成，数据存储，数据处理，数据应用。

### 功能核心

- 1、**研发社区阵地空间管理模块**：AI算法实现态势感知（如通过社区图片和视频、文本，对环境空间质量、绿视率、安全感分数、压抑感分数等.....）
- 2、**社区服务机器人**：门禁控制、视频监控检测
- 3、**社区“微网实格”智慧管理综合服务平台**：党群服务、大数据管理、AI能力管理、与上面两大块的集成。

 **系统核心功能包括：**

-  **智慧党建**：提供社区党建管理、组织架构、成员管理等功能。
-  **社区生活服务圈**：整合本地商家、社区活动信息，实现社区居民服务。
-  **AI 能力管理与提升**：基于 **AI 中台架构**，对接分布式算法服务，支持 **AI 图像分析、视频解析、异常检测** 等能力。
-  **社区机器人管理**：实时监测社区机器人状态，支持远程运动控制。

### 项目亮点

> #### “你项目上线后有没有遇到过性能瓶颈？比如 Redis 的命中率不高，或者线程阻塞等？你是如何排查并优化的？”
>

我们确实遇到过 Redis 缓存命中率低、接口响应变慢的性能瓶颈，具体发生在**社区服务列表查询接口**中。

**问题现象：**

- 监控系统（Prometheus + Grafana）告警接口响应时间大幅上升；
- Redis 命中率低于 60%，数据库 QPS 被打满，CPU 占用飙升；

**排查过程：**

**首先排查缓存命中问题**：

- 使用 Redis 自带命令 `INFO stats` 和 `MONITOR` 查看命中率；
- 发现大量缓存 key 是动态拼接的，存在 key 不统一问题（大小写问题）

**数据库压力分析**：

- 通过慢 SQL 日志分析，发现 service_list 查询未走索引；
- 线程池中部分查询线程 Block，队列堆积严重。

优化方案

Redis 缓存优化：

- **统一缓存 Key 的命名规范**，去掉无意义动态参数，全部小写标准化；
- 设置 **合理过期时间（TTL）**，避免热点 key 频繁重建；
- 引入 **缓存预热机制**，系统启动或数据更新时主动缓存热门数据；

数据库与线程池优化：

- 针对频繁查询接口，**添加联合索引**确保命中；
- 数据分页接口添加 **limit + where 条件组合**，避免全表扫描；
- 优化线程池参数配置：增加核心线程数 + 拒绝策略改为 CallerRunsPolicy；==>由调度者线程执行任务

### 项目吞吐量

**关键接口吞吐量（QPS）**：

- 登录接口：约 **300 QPS**（每秒请求数）
- 查询服务列表：约 **500~600 QPS**
- 数据采集上传接口（异步）：约 **1000 TPS**（每秒事务数）



### 项目提问

> #### MySQL、Redis、HDFS存入什么数据
>

| **存储方式**        | **用途**                                                     | **特点**                                         |
| ------------------- | ------------------------------------------------------------ | ------------------------------------------------ |
| **MySQL**           | 存储**用户管理、社区服务管理、机器人状态管理、日志数据**     | 适合需要事务处理的场景，确保数据的一致性和完整性 |
| **Redis**           | 存储**用户认证信息、缓存热点数据（**社区服务推荐、社区活动信息**）、AI处理结果**、**社区公告**（如停电、停水通知、节日活动）、**党建新闻**（如党组织动态、学习通知）、社区便民服务的静态内容（如服务分类、机构信息） | 适合用于高并发场景的缓存加速                     |
| **HDFS**            | 存储 **社区日志数据、AI 训练数据、监控视频**                 | 适合大规模顺序读写，兼容大数据处理               |
| **对象存储（OSS）** | 存储 **网格图片、用户上传文件**                              | 适合非结构化数据存储，支持 S3 API                |

## JWT

> ##### **你使用了 JWT 进行用户认证与权限控制，能讲讲 JWT 的认证流程和它与 Session 的区别吗？在项目中有哪些优劣权衡？**
>

用户登录后，服务端使用用户的唯一标识（如 userId）和密钥生成一个 **JWT（Access Token）**，并返回给前端。同时生成一个较长时效的 **Refresh Token**（刷新令牌）和权限列表，可存于前端或 Redis。

后续每次前端请求都携带 JWT：

- 服务端通过解析 JWT 判断是否过期、是否合法。
- 若启用了黑名单机制（如登出场景），则可通过 Redis 黑名单校验其是否已失效。
- 如果 Access Token 过期而 Refresh Token 仍有效，可用它换发新的 JWT。
- 查询角色对应权限（可缓存）→ 判断是否包含目标 API 权限

当用户主动登出时：

- 将 JWT 加入 Redis 黑名单（有效期设为 JWT 过期时间+buffer）
- 同时删除 Refresh Token。

> ##### 为什么选择使用 JWT 进行身份认证？相比于 session 有哪些优势和适用场景？
>

至于 JWT 和 Session 的区别：

- JWT 是无状态的，前端自己保存，后端不用记住谁是谁，适合做分布式、前后端分离；
- Session 就是传统的登录机制，用户一登录，服务器会在内存或 Redis 里给他分一个 Session ID，后面请求就带着这个 ID。



我们最后选用 JWT，是因为项目需要做成前后端分离、也考虑到以后可能部署多节点，JWT 方便扩展、不用共享会话状态。缺点是Token 没法手动失效，我们就加了 Redis 黑名单和双 token 的方案来补这个短板。



前后端分离的特点：

1. 前端（Vue、React 等）独立构建、部署，运行在浏览器或移动端；
2. 后端（Java、Node.js、Python 等）仅提供 API 接口，不维护前端页面状态；
3. 双方通过 **HTTP 接口 + Token** 交互，后端不维护用户 Session。

这种架构对认证方式提出了几个要求：

- 客户端要能方便地携带用户凭证；
- 后端能快速验证用户身份，无需存储状态；
- 能支持多端、跨域、安全传输。



> **你提到后端使用了 MySQL + Redis + HDFS 的多源整合，能具体讲讲数据是怎么流动的？比如上传文件/日志数据是如何进到 HDFS 的？**

以文件上传为例，客户端通过HTTP接口以form-data格式上传文件，前端显示传输进度。后端处理请求后将文件存入HDFS（通过API调用），元数据（文件名、路径、时间、上传人、状态等）存入MySQL，并用Redis缓存任务状态（上传进度，完成标志）。下载时先从MySQL查询文件元数据，再根据路径从HDFS获取文件。

 

> **系统支持 AI 控制台，你是怎么对接 AI 模块的？AI任务是怎么触发和管理的？是通过消息队列还是定时任务？**

一般是通过后端接口和远程服务调用

手动触发：用户前端发起AI请求给后端，后端调用AI模块，处理请求，并返回JSION格式的请求结果。



> ##### 你在权限设计中采用了 RBAC 模型，可以详细讲讲 RBAC 的实现细节和优势吗？
>

RBAC的核心概念就是“用户-角色-权限"三层关系

具体实现主要是靠”用户表、角色表、权限表“以及”用户-角色表“，”角色-权限表“五个

主要的权限校验流程：

 权限校验流程（以接口访问为例）：

1. 用户登录，系统返回用户的角色信息（可缓存于 JWT 或 Redis 中）。
2. 用户访问接口，携带 Token。
3. 后端解析 Token -> 获取用户角色。
4. 查询角色对应权限（可缓存）→ 判断是否包含目标 API 权限。
5. 有权限则放行，无权限则返回 403。

Java/SpringBoot：使用 `Spring Security + 注解` 实现权限控制，`hasRole() / hasAuthority()`



> 完整版本用户登录流程
>

1. 输入用户名和密码，后端从数据库中查询，并进行密码对比（bcrypt加盐）
2. 后端生成JWT Token和Refresh Token以及**权限列表（智慧社区）**。JWT返回给前端，其余存储在redis里面
3. 前端访问携带JWT，是否在黑名单、是否过期以及是否有对应权限访问



## HDFS

如何保障上传到 HDFS 的文件安全性和完整性？有没有考虑断点续传或大文件分片？

> 确保HDFS的安全性：

1. 认证+授权==>非管理者权限没办法上传文件
2. 限制文件类型==>没办法上传jpg/MP4/text==>允许上传word、excel、pdf
3. 文件大小限制==>**SequenceFile**：这是 Hadoop 中专门为小文件设计的存储格式，将小文件存储在大文件中，从而减少 HDFS 的存储开销。
4. 上传日志追踪==>记录上传者用户、IP、时间、文件名

> 保障上传文件的完整性：

1.  HDFS 本身校验机制==>HDFS 写入时会自动做 block 校验和（checksum），防止存储损坏
2.  回调确认机制==>上传完成后由服务端返回“上传成功 + 校验成功”确认，再通知前端入库或处理

> 为什么需要断点续传和大文件分片

上传大于 100MB 的文件易超时、上传中断（断网、刷新）会重头上传，体验差

> 分片上传

1. 前端将文件按 1MB / 4MB 等单位切片（如 20 个切片）
2. 每个切片计算 MD5，发送到后端 
3. 后端返回哪些切片已存在（断点续传）
4. 前端只上传缺失的切片
5. 所有切片上传成功后，后端合并为完整文件，并上传到 HDFS

 MD5生成固定长度的哈希值，检查文件完整性。上传方计算文件的 MD5 值并提供给下载方，下载方在收到文件后也计算其 MD5 值，若两者一致，文件没有被篡改或损坏。

> 后端合并策略

多个切片上传到 HDFS 再合并：HDFS 端合并，如使用 `hadoop fs -getmerge`



> **在整合 HDFS 时，你是如何设计文件上传、下载或读取逻辑的？是否有封装统一的工具类？**

 HDFS工具类封装（底层操作）

封装基础功能的接口：

1. 上传：文件上传并返回实际的存储路径
2. 下载：根据路径下载文件
3. 删除：删除指定文件
4. 合并：支持大文件分片合并

使用了 HDFS Java API 和 HDFS Client 统一管理连接、路径规范、异常处理。



HDFS+MySQL元数据封装（业务层服务）==>抽象封装

上传文件流到 HDFS：将文件名、HDFS 路径、上传用户、上传时间、MD5 校验值写入 MySQL；

通过用户 ID 查询文件元信息（数据库）：返回文件访问路径或下载链接（拼接 HDFS 访问地址



接口统一封装和抽象

1. 统一返回结构封装（`Result<T>`），格式为JSON（code：200 msg：“操作成功” data：{}）
2. 接口抽象层设计：接口限流、鉴权、日志注解封装（AOP）



## Spring Scurity

### RBAC

核心思想是，将**权限赋予角色，然后将角色分配给用户**，而不是将权限直接赋给用户。

### **RBAC 模型的基本概念**

1. **用户（User）**：系统中的使用者。一个用户可能会被分配一个或多个角色。
2. **角色（Role）**：代表一组权限的集合。角色是组织内部职位或责任的体现，每个角色定义了执行特定操作所需的权限。
3. **权限（Permission）**：指定用户或角色对资源可以执行的操作（如读取、写入、删除等）。
4. **会话（Session）**：用户与系统的交互时，可以选择一个或多个角色进行访问。会话用于临时配置用户在某一段时间内的角色。

### **RBAC 的核心原则**

1. **最小权限原则**：每个用户只分配其完成工作所需的最低权限，减少潜在的安全漏洞。
2. **角色继承**：一个角色可以继承另一个角色的权限，支持权限的层次化设计。
3. **分离职责（SoD，Separation of Duties）**：为了避免利益冲突，可以将某些权限分配到不同的角色中，避免一个用户拥有过多的权限。



> 是怎么知道用户的权限信息的，是用拦截器还是切面又或者其他方法？

并不是单纯的拦截或者切面。而是通过 **JWT（或Session）+ Spring Security 权限体系** 实现自动识别与拦截

1. 用户登录，系统验证身份，生成JWT和权限列表
2. 每个请求进入系统后，都会先经过 Spring Security 的 **过滤器链**：拦截请求，从 Header 中提取 Token，解析出用户信息。并把解析出的用户权限信息存入安全上下文。接着，Spring Security会根据注解来进行权限判断（推荐在 Controller 或方法上加注解：`@PreAuthorize`、`@Secured` 等）



## MySQL

> 用户的关键信息有没有加密（电话、身份证）

MySQL 提供了内置的**加密函数 `AES`**，可以用于对敏感数据进行加密和解密。这些函数适合加密小型数据，如手机号和身份证号。你需要提供一个加密密钥（对称密钥），该密钥用于加密和解密操作。

**数据脱敏**：对于用户敏感信息，如身份证号、手机号等，可以考虑在查询时对部分数据进行脱敏，只显示部分信息，如显示手机号的后四位或身份证号的最后 4 位。



> 密码加密

用户密码的存储采用的是BCrypt算法（哈希+盐），而不是对称加密或非对称加密。

哈希计算成本一般为12

**盐的长度固定为 16 字节（128 位）**，存储时以 **22 个 Base64 字符表示**

**足够防止彩虹表攻击和哈希碰撞**

> **彩虹表攻击** 是一种**基于预计算哈希值**的密码破解技术。攻击者使用**预先计算的哈希值表**来快速反推出明文密码，而不需要暴力枚举所有可能的密码组合。**盐是随机的**，即使用户 A 和用户 B 的密码相同，哈希值也不一样.

![img](https://i-blog.csdnimg.cn/direct/fe70021423a6424088cb340b04a81db8.png)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)编辑



> **为什么不需要解密？**

- **哈希是单向的**，**不可逆**，即**无法通过哈希值反推出原始密码**。
- **验证过程** 只是**重新对用户输入的密码进行哈希计算**，然后与数据库中的哈希值进行匹配，而**不需要解密**。



> 数据库设计方案



1.将平台功能拆分为多个**业务模块**，每个模块尽量单独建表，逻辑清晰，便于维护

2.社区系统的实体关系围绕“人”--“房子”--“设备”构建，其他服务模块（如安防、通知、报修）围绕这三者展开

3.用户隐私（手机号、身份证号、邮箱等）加密存储、操作日志审计机制、数据库角色隔离权限控制



智慧社区平台
│
├── 用户与权限系统
│   ├── 用户信息（住户、访客、物业）
│   ├── 用户角色与权限
│
├── 房屋与楼栋信息
│   ├── 社区、楼栋、单元、房屋
│
├── 智能设备系统
│   ├── 设备注册与状态（门禁、摄像头等）
│   ├── IoT 设备数据
│
├── 服务中心
│   ├── 报修、投诉、志愿服务
│
├── 安防与告警系统
│   ├── 人脸识别、入侵检测
│   ├── 告警事件与处理记录
│
├── 通知与信息发布
│   ├── 公告、回执、阅读状态
│
│
└── 系统日志与运维
    ├── 登录日志、操作日志、异常日志



核心实体关系思路
1. 用户-房屋关系（1对多）
每个用户可关联多个房屋（如业主名下多套房）、房屋可有多个住户（如家庭成员、租户）

2. 事件-人/房/设备关联（多对多）
    安防告警、服务报修等事件往往同时关联多个实体

3. 用户-权限关系（多对多）
    每个用户有一个或多个角色，每个角色拥有多个权限资源



**地理空间结构建模**

- 建立统一的“社区-楼栋-单元-房屋”四级结构
- 每个房屋唯一 ID，可用于快速索引与定位

 **用户数据建模**

- 将用户分为业主、住户、租户、物业人员等
- 使用“用户表 + 用户扩展表”结构，便于角色扩展和身份管理

**权限模型设计（RBAC）**

- 采用经典的**基于角色的访问控制（RBAC）模型**
- 用户 ↔ 角色 ↔ 权限 ↔ 菜单资源 多对多关系清晰

 **告警与事件系统**

- 所有报警事件使用统一的事件记录表，抽象出**事件类型、级别、状态、处理人**等字段
- 用事件日志关联用户、设备、房屋

**消息/公告建模**

- 建立公告发布表与用户阅读状态表（可支持“是否已读”记录）

**服务处理流程设计（如报修、投诉）**

- 统一使用“任务流+状态机”设计模式
- 各类服务事件应支持生命周期状态流转（待处理 → 处理中 → 已完成）





## Redis

Redis 是如何用于缓存和高并发场景优化的？你做了哪些具体的优化手段？

> ```
> ***Redis 的作用和使用场景***
> ```

 **缓存热点数据**：缓存用户信息、权限列表、热点信息等，避免频繁访问数据库

**消息队列缓冲**：Redis 的 **List / Stream** 可作为轻量级消息队列使用，缓存用户行为日志、告警信息、通知等，缓解系统突发请求压力。



> Redis合理的数据结构

Hash：用户信息、Set:用户权限集合



> ##### ***你提到使用 Redis 实现缓存机制，能详细说说你缓存了哪些数据？具体是如何设计 key、value 的结构？过期时间是怎么设定的？***

缓存一些热点数据，社区公告（如停电、停水通知、节日活动）、党建新闻（如党组织动态、学习通知）、社区便民服务的静态内容（如服务分类、机构信息）等

key

模块前缀+业务标识+ID==>模块:功能:参数

缓存某个社区的公告列表==>社区公告  notice：list：community:{communityId}---通知：列表：社区：社区列表 

缓存单条公告的详情页内容==>公告详情 notice:detail:{noticeId}      

缓存党建新闻列表==>party:list         ==>党建新闻通常是**全社区共享的内容**，不区分小区                    

缓存单条党建新闻详情==>party:detail:{newsId} 

value

JSON 数据格式

{
  "id": "1024",
  "title": "关于4月20日停电的通知",
  "content": "因设备检修，计划于4月20日...",
  "publishTime": "2025-04-15T09:00:00",
  "communityId": "001",
  "type": "紧急通知"
}   



> ***过期策略***

| 数据类型     | 是否实时更新 | 过期时间设置 |
| ------------ | ------------ | ------------ |
| 社区公告列表 | 每天更       | 1小时        |
| 公告详情     | 基本不变     | 1天          |
| 党建新闻列表 | 每天一更     | 30分钟       |
| 新闻详情     | 固定内容     | `12小时      |

> ```
> ***接口响应时间从 1.2s 降到 300ms，你是怎么定位性能瓶颈的？用了哪些具体的优化手段？***
> ```

首先使用JMter进行压力测试，发现redis的访问率比较低，都跑到数据库了。

怀疑：1、redist接口连接出错，没法调用 2、接口没有问题，但数据访问不到 3、接口和数据都没有问题，过期时间设置太短了

经过排差发现，是因为在redis中设置的key出现问题，出现了key值命名不规范（如大小写以及缩写和全写问题）和**动态 key 拼接错误**

参数拼错、顺序错，（ `user:id:123` 查 `user:123:id`），导致找不到对应的key



> 你提到访问速度提升了 53.3%，具体是通过哪些手段实现的？压力测试中使用 JMeter 有什么关键配置？

**后端优化 + 缓存加速 + 数据处理改进 + 异步机制**

1. Redis 缓存引入 & 命中优化：存放热点数据、统计数据等，设置合理的过期时间和key粒度
2. 引入异步处理机制：文件上传、AI状态推送。使用SPring的@Async、@CompletableFuture实现异步任务处理
3. 数据库层优化：对SQL 语句优化：避免嵌套查询、N+1问题、添加索引；

**JMeter 的关键配置和思路**

1. **线程数**：设置为 100~1000 模拟高并发用户
2. **Ramp-Up Period**：设置为 30s，模拟真实逐步并发；
3. **Loop Count**：根据接口类型设置，如文件上传、权限查询、登录验证等；

**结果分析**

1. **平均响应时间**、**吞吐量（Throughput）**、**错误率**是三大指标；



## AOP

> 为什么使用 AOP 实现日志与触发？

**不侵入原始业务代码**的情况下，对某些操作进行：

- ✅ 日志记录（如操作人、操作内容、时间等）
- ✅ 自动触发业务逻辑（如更新缓存、发送通知、同步状态）



> 实现步骤

创建注解@Log、@TriggerUpdate

定义切面类@Aspect



> 触发了哪些业务逻辑

在智慧社区项目中，我们利用 Spring AOP 技术为以下业务模块提供了**统一的日志记录与业务触发处理机制**：

1. **用户上传文件模块**：
   - 使用 `@Log` 注解记录上传行为：记录上传人、上传时间、上传文件路径、文件大小等信息；
   - 使用 `@TriggerUpdate` 注解触发：
     - 触发 Redis 缓存更新；
     - 校验文件 MD5 并记录日志；
     - 支持断点续传的大文件合并触发逻辑。
2. **权限变更模块**：
   - 使用 `@Log` 记录权限变更操作，包括操作人、变更内容、变更时间；
   - 触发更新 Redis 缓存中的用户权限列表（`UserPerm:{uid}`）；
   - 若当前用户在使用系统，触发 WebSocket 强制刷新前端权限或提示重新登录。
3. **居民提交意见反馈模块**：
   - 自动记录提交记录，包括居民信息、提交时间、内容摘要；
   - 同时触发：
     - 后台运营端消息提醒；
     - 将信息写入队列中，支持后台客服或物业的异步处理；
     - 更新社区意见统计数据缓存，用于大屏展示。

------

在外卖服务平台项目中，我们使用 AOP 对订单生命周期进行拦截和管理，实现统一日志和业务联动：

1. **用户创建订单行为切面**：
   - 使用 `@Log` 注解记录订单创建行为，记录：
     - 创建人（用户 ID）
     - 创建时间
     - 订单来源（小程序 / App）
     - 下单地址、设备信息等
   - 使用 `@TriggerUpdate` 注解触发后续逻辑，如：
     - 推送订单通知给骑手系统；
     - 将订单信息写入 Redis 队列，供 AI 推荐模块分析；
     - 同步到大数据平台做实时热销分析。
2. **订单状态变更**（如骑手接单、配送中、送达）：
   - 自动记录状态变更时间、责任人（骑手或系统）；
   - 更新订单状态缓存 `Order:{orderId}`；
   - 若用户关注该订单，通过 WebSocket 实时推送更新给用户；
   - 订单完成后触发积分发放或优惠券模块。



## AI模块

系统涉及 AI 能力展示，具体是通过什么方式接入 AI 模块的？是异步处理还是同步？



> 接入方式：**通过 RESTful API + gRPC + WebSocket 接入 AI 模块**

- **AI 模块部署**：使用独立服务部署 AI 模型（如行为识别、人脸识别），支持横向扩展；
- **调用方式**：
  - 社区摄像头上传帧数据或视频流；
  - 后端通过 **RESTful API** 或 **gRPC** 接入 AI 服务，提交分析任务；
  - AI 模块分析后将结果通过 WebSocket 或消息队列推送给主系统；
- **数据格式标准化**：上传视频帧数据前做格式统一处理（图像转 base64 或临时存储 HDFS 后传路径）；



> 调用方式：**异步处理为主，部分为同步查询**

异步处理（大多数 AI 任务）

- **使用场景**：如视频中的人物行为识别、异常事件检测等；
- **原因**：
  - AI 模型推理时间不确定，耗时操作影响主流程；
  - 用户不需要实时响应，可通过后台任务返回结果；
- **实现方式**：
  - 后端将任务信息写入 Redis ；
  - AI 模块异步拉取任务、处理并将结果推送回主系统（WebSocket / Redis 发布订阅）；
  - 主系统将结果推送到用户界面或记录入库；
- **优势**：不阻塞主线程，系统吞吐量更高。



讲解一下这个：多线程调用:线程池优化，异步外理 A1 任务，线程同步，确保 A 计算任务 并行执行后统一推送 AI任务调度优化:采用 Redis 作为 AI任务队列，支持高并发任务处理，

> “在项目中我们涉及到大量 AI 分析任务处理，我做了一些优化来提升整体效率。我们把一些耗时计算任务，比如 A1 类任务，放到线程池中异步执行，避免主线程阻塞，同时通过线程同步手段，比如 CountDownLatch 来确保所有子任务完成后，再统一推送结果进入 AI 模块。

> 在 AI 任务调度上，我们选用了 Redis 来做任务队列，既可以支持高并发写入，也可以通过消费者服务异步消费。这样可以有效地解耦业务处理和 AI 推理，任务分发也更灵活可控，系统整体的并发能力和容错能力都有明显提升。”

> “我们用 Redis 来做任务队列，生产者将任务写入 Redis 的 List 队列，消费者用 `BRPOP` 阻塞式消费，这种方式特别适合高并发下的异步任务处理。

> 后来我们还用 Redis Stream 实现了一个更可靠的任务分发系统，支持多个消费者组成消费组来处理 AI 推理任务，同时可以对未处理或处理失败的任务进行重试。这让整个任务调度系统的可控性、可追踪性大大提升了。”



Redis 任务队列优点总结（记住这几点，面试可用）

1. **高性能**：基于内存，读写速度极快，适合高并发任务。
2. **轻量简单**：部署、使用门槛低，尤其适合中小型服务。
3. **结构丰富**：List 简单高效，Stream 支持可靠投递、消费组。
4. **可扩展性好**：结合多个消费者/worker 可做分布式调度。
5. **支持持久化+容灾**：数据不容易丢。



# 三、外卖平台服务

### 项目背景

基于SpringBoot的校园点餐平台，项目分为客户端和商家端，商家端主要实现了对员工和菜品的增删改 査以及订单相关数据的查看与分析。客户端基于微信小程序实现了在线点餐、下单、催单等功能。

### 功能核心

![img](https://i-blog.csdnimg.cn/direct/ff9fa2603fec43ca83b3cc3fa06a32a8.png)

### 项目亮点

> #### 数据库设计上有没有做过分库分表、索引优化等？能不能举个优化后明显提升的例子
>

场景：在订单模块中，由于每个用户每天可能产生多个订单，订单表只有一个，**订单表数据量迅速增长，查询变慢，偶尔还会出现锁等待**问题。

**【优化手段一：分表设计】**

我们按 **user_id 取模分表**，将 `order` （订单）表分成了 `order_0`、`order_1`、...，一共 10 张表：

**1、路由逻辑封装成工具类，`user_id % 10` 路由到对应分表；**

```java
//所谓“路由封装为工具类”，就是指我们不直接在代码里写：
int tableIndex = userId % 10;
String tableName = "order_" + tableIndex;
而是写成这样：
String tableName = OrderTableRouter.getTableName(userId);
```

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)把路由逻辑封装成工具类，是为了做到业务代码无感知、统一管理路由规则、方便扩展路由策略、支持未来自动扩容和动态配置，是高可维护性系统设计的基本功



**2、利用 MyBatis 拦截器动态修改 SQL 实现透明分表；**

```sql
//表面上访问
SELECT * FROM order WHERE user_id = 123;
//实际上访问
SELECT * FROM order_3 WHERE user_id = 123;
```

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)需要一个 **“SQL 重写机制”**：根据 user_id，自动把 SQL 中的表名 `order` 改成 `order_3`

需要使用**MyBatis拦截器**：拦截原始 SQL → 根据 user_id 动态改写 SQL 表名 → 放行执行

MyBatis 拦截器可以在以下生命周期阶段插入自定义逻辑：

1. **Executor** 拦截执行器（执行 SQL 之前）；
2. **StatementHandler** 拦截 SQL 预处理；
3. **ParameterHandler** 拦截参数填充；
4. **ResultSetHandler** 拦截结果处理。

通常在 **StatementHandler 的 prepare 阶段** 动手脚，在 SQL 执行之前

**优势有很多**，核心是：**做到“业务代码无感知”**！👇

| 对比项         | 用拦截器             | 自己拼接 SQL                  |
| -------------- | -------------------- | ----------------------------- |
| 💡 路由逻辑     | 集中封装，统一管理   | 分散在各个 DAO 里             |
| ✨ 对业务透明   | ✅ 调用方法不变       | ❌ 每次写 SQL 都要加逻辑       |
| 🧼 SQL 语义清晰 | 仍然写 `order` 表    | 要写成 `order_${userId % 10}` |
| 🔧 运维改动小   | 改路由策略只动拦截器 | 改一次要改 N 个地方           |
| ☠️ 出错风险     | 小，统一测试         | 高，容易出错、SQL 注入风险    |



**3、分表后单表数据量大幅下降，JMeter显示查询和插入性能平均提升 50%+。**

> 补充说明：考虑后期数据迁移与分片路由扩展，我们还预留了“路由策略注册中心”的抽象接口，支持后期平滑扩容。

【优化手段二：索引优化】

我们通过慢 SQL 日志发现 `order_status` + `create_time` 的组合查询频率非常高：

**订单状态查询**（比如查看订单是否已完成、取消等）和 **时间范围查询**（比如查询某个时间段内的订单）。

```sql
SELECT * FROM order WHERE user_id = ? AND order_status = ? ORDER BY create_time DESC LIMIT 20
```

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)**原本只在 user_id 上有索引，导致全表扫描；**

👉 优化后新增联合索引：

```sql
CREATE INDEX idx_user_status_time ON order(user_id, order_status, create_time DESC);
```

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

- 查询耗时从 800ms 降低到 80ms；
- 慢 SQL 日志该类语句几乎消失。

> 补充说明：
>
> 删除了一个无效的冗余索引（user_id 单列），减少了写入时的索引维护开销；
>
> 利用 `EXPLAIN` 分析执行计划，确保走覆盖索引。

 **explain关心的字段**

![img](https://i-blog.csdnimg.cn/direct/73b3649aad7643bea6903758317f9041.png)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)编辑

使用 `EXPLAIN` 命令时，重点关注以下几个方面：

- **连接类型** (`type`)，确保使用高效的索引扫描。=> ALL全表扫描、index索引扫描、range范围扫描、`ref`基于索引的查找
- **实际使用的索引** (`key`)：显示实际使用的索引。如果为 `NULL`，说明没有使用索引，可能进行了全表扫描
- **行数预估** (`rows`)：显示查询计划预估需要扫描的行数。这个数字越小，通常意味着查询越快。
- **额外信息** (`Extra`)：警惕 `Using filesort` 或 `Using temporary` 这类可能影响性能的操作。



【优化手段三：查询+订单状态】

一、为什么不直接设计两个接口分别连接历史订单和待完成订单？

1. **分表的初衷是按 user_id 均匀分布数据，和订单状态无关**

- `order_0 ~ order_9` 是基于 `user_id % 10` 分表的，这种方式是为了**均匀分布数据和压力**。
- 如果你再按“订单状态”去设计两个接口连接不同表，那就不再是均匀分布的访问，会造成访问热点。

例如：

- 如果“待完成订单”只存在于 `order_3` 和 `order_7` 中，某个接口就会访问这两张表很频繁。
- 导致数据库连接不均衡、单表压力增大、缓存命中率降低等问题。

2. **订单状态是业务字段，变动频繁**

- 一个订单从“待接单” → “配送中” → “已完成”。
- 如果按“状态”建表或设计接口，那状态变化就要“移动订单数据”，或者让接口逻辑复杂化（多表 join 或 union all）。



二、 **冷热数据分离（归档历史订单）**

如果订单量特别大，**历史订单占据了大量空间和性能瓶颈**，可以：

- 把“历史订单”定期归档到 `order_history_x` 表
- 新订单留在 `order_x` 表

这样做的前提是：

- 历史订单访问频率非常低
- 查询历史订单容忍一定的延迟

那么接口层就可以这样设计：

- 查询待完成订单 → 连主表 `order_x`
- 查询历史订单 → 连归档表 `order_history_x`



### 项目吞吐量

- **下单接口的吞吐量**大约在 **400~500 QPS**，因为会涉及库存校验、订单生成、RabbitMQ 推送等多个环节；
- **WebSocket 推送能力**：单服务器可以支撑 **2000+ 长连接**，做了心跳检测机制，响应延迟控制在 **100ms 以内**；
- **RabbitMQ 消息消费能力**：我们用多线程 + 手动 ack 的方式做了消费者优化，能做到每秒处理约 **800~1000 条消息**；
- **SpringTask 定时任务**（订单超时取消）：使用线程池并发调度，最多支持每分钟处理上千个待处理订单。



## Redis(本地部署)

> #### Redis做为缓存，mysql的数据如何与redis进行同步呢?(双写一致性)
>

- 在智慧社区项目中，我们当时是把热点新闻的数据存入到了缓存中，虽然是热点数据，但是**实时要求性并没有那么高**，所以，我们当时采用的是异步的方案同步的数据
- 在外卖平台中，我们当时是把菜品的库存纳入缓存中，需要**实时的进行数据同步**，为了保证数据的强一致,我们当时采用的是redisson提供的读写锁来保证数据的同步

**允许延时一致的业务，采用异步通知**

- **延时双删策略**：先删除缓存，更新数据库，使用MQ中间件，通知缓存删除
- **订阅binlog日志：**利用canal中间件，伪装为mysql的一个从节点，通过读取binlog数据更新缓存

**强一致性的，采用Redisson提供的读写锁**

- 共享锁:读锁readLock，加锁之后，其他线程可以共享读操作
- 排他锁:独占锁writeLock也叫，加锁之后，阻塞其他线程读写操作



> **Redisson**

**分布式读写锁**：分别对缓存和数据库中的分布式加锁，持有写锁线程先更新数据库，再更新缓存，最后释放锁。

**锁续期机制**：Redisson 内部提供了“看门狗”机制，默认锁的有效期为 30 秒。如果在锁持有期间，持锁的 Redisson 实例未关闭，锁的有效期会自动延长，避免因 Redis 节点宕机导致的锁死问题。



**分布式锁**

> 分布式解决问题

**❌ 问题 1：超卖**
 多个用户同时下单，库存 = 1，但两个人都成功购买，导致**库存变负数**。

**❌ 问题 2：订单重复提交==重复消费**
 同一个用户点击**多次提交订单**，导致创建多个相同订单。

**消息幂等性**：**避免消息重复消费导致数据库数据错误**：

- 使用 **唯一 ID**（如订单号）来标记已消费的消息，防止重复写入数据库。
- 可以在 **数据库增加唯一约束**，避免重复插入相同数据。

**❌ 问题 3：并发写入数据覆盖**
 多个用户同时修改购物车，可能导致**数据丢失或错误**。

**解决方案**

- 悲观锁：确保同一时间只有一个用户对库存进行操作，避免多线程冲突
- 乐观锁：根据商品的版本号进行更新库存操作，只有开始的版本号与提交的版本号一致才行
- 使用 **Redis 分布式锁** 确保**扣库存操作是原子的**，防止并发问题



> 如何实现

在redis中提供了一个命令setnx(SET if not exists)，由于redis的单线程的，用了命令之后，只能有一个客户端对某一个key设置值，其他客户端是不能设置这个key的



> 那你如何控制Redis实现分布式锁有效时长呢?

**Redisson 的自动续约机制：** 通过 **看门狗（Watchdog）** 自动延长锁的有效期。获取锁后，默认超时时间为 **30 秒**，但 Redisson 会 **每 10 秒** 续约一次，确保锁不会过期，直到业务逻辑执行完成后手动释放锁，避免因业务执行时间过长而导致锁提前失效。

还有一个好处就是，在高并发下，一个业务有可能会执行很快，先客户1持有锁的时候，客户2来了以后并不会马上拒绝，它会不断尝试获取锁，如果客户1释放之后，客户2就可以马上持有锁，性能也得到了提升。==自旋锁



> redisson实现的分布式锁是可重入的吗?

**可重入锁** 是指 **同一个线程** 在**持有锁的情况下，可以再次获取同一个锁，而不会发生死锁**。**Redisson** 也实现了 **分布式可重入锁**，让**同一线程** 在分布式环境中多次加锁，不会被自己锁住。



> redisson实现的分布式锁能解决主从一致性的问题吗

这个是不能的，比如，当线程 1 加锁成功后，主节点数据异步复制到从节点时，如果当前持有 Redis 锁的主节点宕机，从节点被提升为新的主节点，但**锁的同步尚未完成，新主节点上没有该锁的记录，此时其他线程可能会重新获取锁并修改数据，导致多个线程对同一资源进行并发修改，从而造成数据不一致的问题**



> redis分布式锁的粒度--按业务粒度分类

| **锁类型**   | **锁定范围**                   | **适用场景**                               | **优缺点**                                           |
| ------------ | ------------------------------ | ------------------------------------------ | ---------------------------------------------------- |
| **全局锁**   | 整个系统或应用                 | **重大业务操作**，如定时任务、数据库表迁移 | 适用于保证全局数据一致性，但会降低系统并发性能       |
| **业务级锁** | 业务操作（如订单、支付、库存） | **如支付事务、订单状态变更**               | 控制特定业务的并发，避免多个线程同时修改关键业务数据 |
| **资源级锁** | 具体的资源（商品 ID、用户 ID） | **如商品库存扣减、用户账户操作**           | 降低锁冲突，提高并发性能                             |



## ThreadLocal

> 如何管理用户上下文

实现逻辑（结合登录拦截器 + ThreadLocal 工具类）

自定义用户上下文工具类，从JWT解析获取用户信息



> 是否存在线程复用 / 内存泄漏问题？

**存在：线程不会销毁而是复用**，如果不手动 `remove()`，上一个请求遗留的用户信息可能“污染”下一个请求，造成严重的数据安全问题；



> 为什么使用ThreadLocal?

如果每个请求都手动解析 `token` 并传递用户信息，可能会导致：

- **代码侵入性高**，需要在每个方法中传递 `token` 解析结果，影响代码结构。
- **并发问题**，如果多个线程共享同一个 `token` 解析结果，可能导致数据错乱。

> **`ThreadLocal` 方式的优势**

- **避免参数层层传递**：解析 `token` 后，将用户信息存入 `ThreadLocal`，整个请求链中的 **拦截器、服务层、控制器** 都能直接获取用户信息。
- **线程安全**：`ThreadLocal` 变量 **仅对当前线程有效**，不会被其他线程访问，避免并发数据混乱问题。

**JWT 适用于整个访问过程**，每次请求都应携带 JWT 令牌。为了**减少重复解析 JWT 的开销**，我们在解析 JWT 后获取 **用户 ID 和权限信息**，存入 **ThreadLocal**，在请求周期（单个线程）内使用，避免多次解析 JWT。

人话：如果我发起一个请求，携带JWT，但该请求可能包含多个操作，每个操作不可能多次验证JWT，所以我使用ThreadLocal来存储这个JTW的用户信息，确保多次操作能够对应上

> ##### 如何使用ThreadLocal来存储和管理用户认证信息

在项目中，如何使用ThreadLocal来存储和管理用户的认证信息?
 (1)**初始化:**在拦截器的 preHandle方法中，从请求中提取JWTToken，并进行校验。一旦校验通过，就把用户的信息从Token中解析出来，并存储到ThreadLocal中。

(2)**使用**:由于 `ThreadLocal` 变量在整个线程内有效，可以直接获取用户信息，而不需要传递 `userId` 参数。这样做的好处是，它消除了通过方法参数传递信息，使得方法签名更简洁、逻辑更清晰。

(3)**清理**:在请求的生命周期即将结束时，例如在返回响应之前，需要显式清除ThreadLocal中的数据。在拦截器的afterCompletion方法中完成清理，确保每个请求结束后清理掉所有关联的数据，防止内存泄漏。

> ##### 内存泄漏

如果在业务处理完成后未及时清理ThreadLocal存储的数据，这些数据会一直存在于对应线程的ThreadLocalMap中，导致垃圾回收器无法释放这些对象，从而引发内存泄漏。

因为ThreadLocalMap是由一个个Entry构成的数组，并且每个Entry的key是弱引用，这就意味着当触发GC时，Entry的key也就是ThreadLocal就会被回收。如果此时value外部也没有强引用指向的话，那么这个value就永远无法访问了，按道理也该被回收，但是由于entry还在强引用value。那么此时value 就无法被回收。

- 每次使用完毕之后记得调用一下remove()方法清除数据
- ThreadLocal变量尽量定义成static final类型，避免频繁创建ThreadLocal实例。

> ##### 数据污染

由于线程池中线程会被复用，未清除的ThreadLocal数据可能在下次任务中被错误地使用，进而引发数据污染问题。

在合适的时机手动调用ThreadLocal.remove()方法来清除ThreadLocal中的数据。这样可以确保每个请求或任务开始时ThreadLocal中不会包含上一次请求或任务的数据，从而保证了数据的独立性和正确性。



## RabbitMQ

高并发场景下，写操作通过消息队列异步执行，减少数据库瞬时压力。**

基于AMPQ协议，主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。更多用在企业系统内，对数据一致性、稳定性和可靠性要求很高的场景，对性能和吞吐量的要求还在其次。



> ##### 消息可靠性：RabbitMQ-如何保证消息不丢失

  当时MYSQL和Redis的数据双写一致性就是采用RabbitMQ实现同步的，这里面就要求了消息的高可用性，我们要保证消息的不丢失。主要从三个层面考虑

- 1️⃣ **开启生产者确认机制**，确保生产者的消息成功到达 **Broker（RabbitMQ 服务器）**。如果发送失败，生产者可以**记录日志**，并根据日志进行**数据补偿**。
- 2️⃣ **开启持久化功能**，确保消息在 **未被消费前不会丢失**。其中，**交换机、队列、和消息都**需要开启持久化，以防 RabbitMQ 服务器宕机导致数据丢失。
- 3️⃣ **开启消费者确认机制，模式为 `AUTO`**。当 Spring 处理完消息后，会自动 **ACK（确认消息已消费）**。同时，我们设置了**最大重试次数为 3 次**，如果 3 次重试仍然失败，则**将消息投递到异常交换机（Dead Letter Exchange, DLX）**，由人工处理。



> ##### **消息幂等性：避免消息重复消费导致数据库数据异常。**

- 1️⃣ **使用唯一 ID（如订单号）** 作为消息的全局唯一标识，在数据库或 Redis 记录已消费的消息，防止重复写入。
- 2️⃣ **在数据库增加唯一约束**（如基于订单号的唯一索引），防止同一数据被重复插入。
- 3️⃣ **采用事务性操作**，确保**消费逻辑和记录唯一 ID 的操作**在同一事务中执行，避免因异常导致状态不一致



> ##### 是如何配置 RabbitMQ 的？使用了哪几种 Exchange 类型？具体在哪些场景用了消息队列？

我在项目中使用 RabbitMQ 主要用于系统解耦、异步处理任务、以及延迟队列功能。在配置上，使用 Spring Boot 的 spring-boot-starter-amqp 进行自动化配置，通过注解或 Java 配置类声明队列、交换机和绑定关系。使用了 Direct、Fanout、Topic 三种 Exchange 类型：

Direct 用于订单模块中的库存锁定；

Fanout 用于用户行为后的多渠道通知；

Topic 用于 AI 模块的任务分发和状态通知；

此外，还设计了延迟队列用于订单超时关闭，提升了系统的用户体验和处理效率。



> 应用场景

**(1) 订单系统：秒杀 / 外卖 / 电商高并发下的数据库优化**

秒杀、外卖、双 11 活动等场景下，大量用户并发下单，数据库瞬间写入压力过大，可能导致**死锁、事务冲突、数据库崩溃**。

![img](C:\Users\99641\Pictures\图\cb71c548c9884b3fba1df573a57704b2.png)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)编辑

在外卖订单场景下，大量用户并发下单时，我们**先在 Redis 预扣减库存**，并将订单请求写入 **MQ 消息队列**。由异步消费者**批量读取订单信息，并写入数据库。**

- 如果数据库操作成功，则**同步更新 Redis 中的库存**，确保数据一致性。
- **如果数据库写入失败**，则触发**库存回滚**，恢复 Redis 预扣减的库存，防止数据不一致。

**（2）订单状态更新**

外卖平台的**订单状态**（已下单、已支付、已完成）需要频繁更新，直接写数据库会导致**大量 update 操作**，影响数据库性能。

### ![img](https://i-blog.csdnimg.cn/direct/c2fc33afcf6b4b2da6c79bf75ce9eef1.png)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

**订单状态变更时**，将变更信息**放入 MQ 队列**，由异步消费者读取并**更新数据库**。



> **为什么不用kafka**

1订单支付、状态更新必须严格按顺序执行。

- **RabbitMQ 支持事务和 ACK 确认机制**
- **Kafka 没有内置事务，无法保证严格的订单消息顺序！**

2.适合短生命周期的消息队列

- **RabbitMQ 是短生命周期消息的最佳选择**：消息被消费后**立即删除,毫秒级延迟**
- **Kafka 适用于日志、监控等长生命周期的数据流，不适合短时事务！**

3.适合处理订单超时

- **RabbitMQ 支持** **TTL（Time-To-Live）+ 死信队列（DLX）**：订单消息进入 **延迟队列;**超时后，消息被路由到 **死信队列**;消费者监听死信队列，执行**订单取消操作**
- **Kafka 没有 TTL 机制**，只能依赖应用程序手动轮询，性能较差。



> **Kafka 更适合大数据分析，不适合事务处理**

**Kafka 适用于**：

- **日志存储**（存储时间长，用户行为分析）
- **实时数据流**（如用户个性化推荐、ETL 数据处理）
- **分布式事件驱动架构**（微服务解耦）



## WebSocket

> 背景

商家接单提醒、骑手订单更新、用户配送状态更新



> 缺点

**网络依赖强：**客户端与服务器之间的网络不稳定，WebSocket 连接容易中断。--心跳机制

**消息乱序**：WebSocket 本身会确保消息的顺序性，但当网络中断或连接恢复时，消息的顺序可能会发生错乱。===>消息队列

**消息丢失**：WebSocket 本身不提供消息持久化功能，因此，如果连接断开或客户端失去连接，未接收到的消息可能会丢失。===>RabbitMQ持久化机制

**资源消耗**：WebSocket 是长连接协议，每个连接会占用一定的内存和 CPU 资源。对于每个客户端，服务器需要保持一个开放的连接和实时通信通道，这可能导致在大量用户连接时占用大量服务器资源。



> 断线重连机制的设计方案

1、客服端自动重连==>前端定时检测WebSocket状态，发现关闭自动重连，设置最大重连次数

2、服务端维护用户连接映射表==>将用户ID与WebSocket绑定，重连后自动替换旧连接，确保保留活连接



> 如何防止消息丢失？（**核心重点**）

1. 推送消息先进入消息队列（如 RabbitMQ）进行异步投递。如果此时 WebSocket 连接断开，消费端会识别推送失败，可将消息转存至 Redis 离线消息列表，待客户端重连后再补发。
2. 服务器发送消息前判断用户的 WebSocket 是否在线；如果不在线，则将消息标记为【离线】，存入 Redis 等缓存中，待用户重连后拉取。
3. 客户端重连成功后，会触发消息拉取请求，服务端从 Redis 离线消息列表中查询并补发未送达消息

推送消息时，先写入消息队列（如 RabbitMQ）实现异步处理。如果 WebSocket 连接断开，消费端检测失败后会将消息标记为离线，存入 Redis 等缓存。客户端重连时主动触发离线消息拉取，由服务端从 Redis 查询后补发，确保消息不丢失。



> 心跳 + 客户端 ACK

心跳机制：每30秒客户端向服务端发送 ping，服务端返回 pong，判断连接存活

**客户端 ACK 机制**：推送消息附带 messageId，客户端收到后返回确认，服务端才标记消息已送达



## Spring Task

启动定时任务@SpringBootApplication、@EnableScheduling

## AOP

在外卖服务平台项目中，我们使用 AOP 对订单生命周期进行拦截和管理，实现统一日志和业务联动：

1. **用户创建订单行为切面**：
   - 使用 `@Log` 注解记录订单创建行为，记录：
     - 创建人（用户 ID）
     - 创建时间
     - 订单来源（小程序 / App）
     - 下单地址、设备信息等
   - 使用 `@TriggerUpdate` 注解触发后续逻辑，如：
     - 推送订单通知给骑手系统；
     - 将订单信息写入 Redis 队列，供 AI 推荐模块分析；
     - 同步到大数据平台做实时热销分析。
2. **订单状态变更**（如骑手接单、配送中、送达）：
   - 自动记录状态变更时间、责任人（骑手或系统）；
   - 更新订单状态缓存 `Order:{orderId}`；
   - 若用户关注该订单，通过 WebSocket 实时推送更新给用户；
   - 订单完成后触发积分发放或优惠券模块。



# 四、项目总结

（1）第一个感觉是思维的解放。

在这么多业务的练习中，我的对于业务的抽象能力大大提升，简单的讲：我认为代码的编写，实际上就是对业务需求的不断解构，拆分，细化。

例如：实现购物车接口。最初我还在想：如何让用户端购物车可以自动显示添加的菜品这些内容。因为没有办法把该业务抽象拆分为具体的代码思路而感到厌烦。之后就明白了，其实就是建立一张表，买了啥都记到表里面，所谓的添加商品可以实时看到，只不过是加了一个数据库查询之后回显给前端而已

这就是我想要说的，**再复杂的业务也可以不断的进行抽离，拆分，最终变为一个个简单的逻辑代码，而谁的抽象拆分能力越强，谁就越可能成为一位合格的程序员。**

（2）第二个感觉是思维的提升。

回头望去，原来自己学习到了这么多的知识点，并且也没有自己最开始认为的那么难。回顾整个项目，我认为作为初写项目的学生来讲，我面临的最大的问题是：缺乏宏观思想。我在写业务代码的时候，**通常只能局限于仅仅实现当前业务，并没有思考代码复用性，业务通用性，逻辑顺畅性这些问题。导致写了很多的功能相同的代码。四个字总结：站位不高。**

而这也是我尝试写项目总结的原因，项目总结让我脱离具体的业务板块，不再把思维聚焦在某一个功能的实现上，而是尝试聚焦整个业务整体。在我的眼里，实现项目是从小到大，我用一个一个业务去组成了这个大的项目。而写项目日记是从大到小，当我从一整个项目整体开始拆分业务的时候，我是切身实地的觉得我的站位变高了，因为我在真真切切的思考不同业务代码之间的逻辑关系。由于实现过整个业务，我可以让思维在不同的业务之间穿梭，不断的解构这些业务。尝试探寻更好的业务解决方案。

我认为：如果我可以在业务逻辑代码搭建阶段就有这种宏观思考的能力，那么整个项目的业务逻辑实现就会变的轻松很多。

# 五、测开知识问答

## 后端转测开

**1. 思维模式的转变**

- **从构建者到验证者**：
  后端开发关注功能实现，而测试开发更关注**质量保障**和**风险预防**。需要培养「破坏性思维」——主动思考如何让系统失效（如边界条件、异常场景）。
- **用户视角**：
  测试需要模拟用户行为，而开发者容易陷入「实现逻辑正确」的假设盲区。

------

**2. 技术栈的补充与调整**

**必学新技能**：

- **自动化测试框架**：
  Selenium（Web）、Appium（移动端）、Pytest/Robot Framework（接口自动化）。
- **持续集成/交付（CI/CD）**：
  Jenkins、GitLab CI 的测试集成，了解流水线中测试环节的触发逻辑。
- **测试专用工具**：
  Postman（API测试）、Jmeter（性能测试）、Allure（测试报告）。
- **代码能力复用**：
  后端开发的编程经验（如Java/Python）可直接用于编写自动化测试脚本。

**可降维的技术**：

- 数据库/API等后端知识仍是优势，但无需深入优化SQL或设计高并发架构。

------

**3. 测试领域的核心概念**

- **测试金字塔**：
  单元测试（开发者已熟悉）→ 接口测试（重点）→ UI测试（成本高，尽量少）。
- **质量指标**：
  覆盖率（代码/需求）、缺陷密度、MTTR（平均修复时间）等。
- **非功能测试**：
  性能测试（如TPS、响应时间）、安全测试（OWASP Top 10）等，这是后端经验的加分项。

------

**4. 流程与协作的变化**

- **左移测试**：
  参与需求评审，早期发现设计漏洞（后端经验可帮助识别技术风险）。
- **缺陷管理**：
  学习用Jira等工具跟踪Bug，编写清晰的重现步骤（避免开发者的「默认已知」表述）。
- **与开发者的沟通**：
  用技术语言说服开发修复Bug（例如通过日志、代码片段定位问题）。

------

**5. 职业发展的差异化**

- **核心竞争力**：
  后端转测试开发的独特优势是**「懂系统底层」**。例如：
  - 设计更精准的异常测试用例（如数据库事务失败、缓存穿透）。
  - 搭建高可用的测试框架（如分布式测试执行）。
- **避免陷阱**：
  不要只做「写脚本的工具人」，要深入业务逻辑和质量体系设计。

从后端开发转向测试开发（或质量保障工程方向）的动机因人而异，但通常可以归纳为以下几类原因，结合行业现状和职业发展逻辑来分析：

------

## 为什么要测开

​        后端开发更偏向垂直领域（如高并发、分布式），而测试开发要求横向技术栈（自动化、CI/CD、监控等），适合希望拓展技术视野的人。部分开发者认为测试开发岗位对「纯编码能力」的要求相对温和，职业生命周期可能更长（但需注意：高级测开同样需要强技术实力）。
​     随着DevOps和云原生普及，企业对质量保障的投入从「人工测试」转向「自动化+平台化」。懂开发的测试工程师（SDET）更吃香，薪资与后端差距缩小。互联网企业收缩后，更看重用自动化测试降低人力成本，测开岗位需求反而稳定。

------

**3. 个人特质与兴趣匹配**

- **细节导向型人才**：
  享受发现隐藏Bug、设计边界用例的成就感（类似解谜游戏），而非长期面对业务逻辑开发。
- **工程化偏好**：
  更喜欢搭建测试框架、开发提效工具（如造数据平台、用例生成器），而非业务CRUD。
- **沟通优势的转化**：
  测试开发需要频繁协调开发、产品、运维角色，适合擅长跨团队协作的后端开发者。

------

**4. 工作负荷与平衡**

- **节奏差异**：
  测试开发的紧急上线压力可能小于后端（但版本发布前同样高强度），适合追求相对可控工作节奏的人。
- **风险责任差异**：
  后端直接对线上故障负责，而测试开发更侧重风险预防（心理压力分布不同）。

------

**如何判断自己是否适合？**

- ✅ 对「质量保障」有热情：
  例如看到代码覆盖率提升、缺陷拦截率数据会感到满足。
- ✅ 喜欢「工具创造者」角色：
  更愿意开发一个自动化测试平台，而非每天手动执行测试用例。
- ✅ 具备「防御性编程」思维：
  写代码时会自然考虑异常场景，这与测试思维高度契合。

------

**转型后的潜在发展路径**

1. **技术专家路线**：
   测试工具研发 → 质量中台架构师（如设计全公司级测试平台）。
2. **管理路线**：
   测试负责人 → 质量效能总监（推动DevOps中的质量门禁）。
3. **跨界路线**：
   转SRE（稳定性工程）或解决方案工程师（客户侧质量咨询）。

------

**建议**：如果转型是因为对质量工程有真实兴趣，或看中技术多样性，这是一个值得的选择；如果单纯因为「后端卷不动」，可能需要重新评估——任何岗位的高阶竞争同样激烈。测开的优势在于**「开发+测试」的复合能力**，而非「退而求其次」。

## 对测开的理解

测试开发的本质应该是“懂开发的测试”，是为了更好的服务产品的“质量”。由于对于目前测试的工作要求，已经不是传统的测试岗位所能胜任的了，我们除了简单的操作层面的“测试”工作，还需要考虑到从测试设计到数据准备到风险控制以及研发效率提升等各个方面，我们需要将我们的工作上升到价值层面的“质量保障”

**角色定位**

「开发质量的守门人 + 效能提升的工程师」

- 不是单纯「找bug」，而是通过技术手段**降低bug发生率**（如精准测试、代码染色）
- 不是被动执行用例，而是**设计质量防线**（如监控告警、混沌工程）

**技术栈维度**

- **自动化体系**：
  - 分层自动化（单元/接口/UI）
  - 框架设计能力（如基于Pytest封装业务断言库）
- **持续交付**：
  - 流水线集成（Jenkins/GitLab CI）
  - 质量门禁（覆盖率/静态扫描卡点）
- **专项测试**：
  - 性能测试（JMeter/LoadRunner）
  - 安全测试（OWASP ZAP渗透）

## 测试开发

一、单元测试

测试**最小功能单元**是否能按照预期运行

二、接口测试

验证**服务之间的通信是否正确**，常用于**后端 HTTP 接口、微服务接口、模型 API 接口**的测试。

1、基础功能性测试

请求方法是否正确、参数校验、状态码检查

2、边界和异常测试

1. **空值 / 极限值**

- 空字符串、超长字符串、最大最小值、特殊字符等边界情况是否处理得当。

2. **重复提交 / 幂等性**

- 重复请求是否会产生多次副作用（比如多次下单）。
- 是否支持 `幂等令牌`（Idempotency Key）。

3. **非法调用场景**

- 非登录状态下访问受限接口是否能拦截。
- 权限不足是否能正确拒绝。

3、安全性验证

    1. **身份认证与授权**

- 是否有 token / session 验证机制。
- token 过期后是否能正确处理。
- 权限是否能覆盖角色管理逻辑（RBAC / ABAC）。

4、性能与稳定性

    1. **接口响应时间**

- 是否在预期时间内响应（如<200ms）。
- 是否支持流式返回（尤其大模型接口）。

2. **并发压力测试**

- 并发访问下是否会出错（如连接池枯竭、响应阻塞）。
- 支持高并发时是否会出现数据错乱、死锁。

3. **重试机制**

- 网络抖动/服务器重启下，客户端是否能自动重试。

三、UI测试

模拟用户在浏览器上的完整操作路径，验证 **页面、交互逻辑、流程完整性**。



# 六、面试闲聊

### 职业规划

我的职业规划是朝着后端开发与大数据方向深入发展，短期内，我希望通过在实习中系统参与实际项目，打磨自己的编码能力、理解业务逻辑，并熟练掌握像 Hadoop、Spark、Flink、Kafka 等核心组件的使用。

中期来看，我希望能独立负责一个小模块的开发与优化工作，逐步积累从数据采集、清洗、治理、到服务化的完整经验，提升系统设计能力和工程落地能力。

长远来看，我希望能成为一名既懂技术又了解业务的工程师，能够在系统设计、性能优化、团队协作等方面发挥更大的价值。

而中电信人工智能公司提供的实习岗位和在数据中台方向的技术实践，刚好与我的发展方向高度契合。我希望借助这个平台不断学习、沉淀、成长。

### 优点

有责任心：在负责“微网实格”智慧社区综合服务平台项目中，我承担了系统架构选型、数据库设计和后端接口开发等核心任务。为了保证项目进度，我制定了详细的开发计划，每周都会向指导老师提交阶段性汇报文档和演示结果，及时沟通并根据反馈进行优化，确保各模块按时高质量完成。

乐于助人、关心他人：在实验室有同学遇到论文排版和数据处理方面的问题时，我主动提供技术帮助，耐心陪同学一起查找问题；在生活中，也经常留意同伴的情绪变化，当他们因科研压力或生活烦恼感到焦虑时，我会主动陪伴、倾听与鼓励，帮助他们缓解情绪。

适应能力强：课题涉及我之前不熟悉的分布式文件系统（如HDFS）。我用两周时间系统性学习相关知识，阅读大量文献与开源文档，迅速掌握了其架构与接口开发方法，并成功独立完成了文件上传下载模块的编写与优化，得到了团队导师的肯定。

学习能力强：面对项目涉及的多种技术，我通过自学和查看，掌握核心用法，并能在项目中灵活应用。例如，我成功将ECharts图表与Flink处理结果对接，实现了社区视频监控数据的实时可视化展示。

### 缺点

“我目前在项目中能独立完成后端模块开发，但在整体架构设计方面的系统性思考还不够。”

“比如面对复杂业务拆分时，虽然可以根据需求完成接口编写和数据库设计，但有时候在模块划分、解耦层次、甚至选型上还不够前瞻，依赖于已有框架或者老师/团队的设计方向。这会导致有些模块扩展性不强，后期维护起来稍显复杂。”

“最近我也开始有意识去补这块短板，也在研究一些开源项目的模块拆分方式，尝试提升自己在架构层面建模和抽象能力，希望从‘能做’逐步转向‘能设计’。

### 加班看法

对我来说，加班本身不是问题，我愿意为了项目进度，投入更多时间和精力。特别是在刚进入职场的阶段，我更看重积累经验和锻炼能力，有时候加班反而是一种成长的机会。

当然，我也更倾向于高效工作而不是无效加班，我会在日常中做好时间管理，在工作时间内保质保量完成任务。如果遇到突发情况要加班，我也会积极配合，希望能和团队一起追求高效、有序、有成果的工作节奏，确保团队整体目标的推进。

### 你还应聘过哪些公司?

我目前主要集中在大数据和后端开发相关的岗位进行投递，比较看重企业在数据处理平台、分布式系统等方向上的技术积累。

之前也有了解像华为云、京东科技这些有大数据中台方向的部门，也参与了一些初步面试，但我对中电信人工智能公司这边特别感兴趣。一方面是因为你们在智慧城市、数据中台领域的实际落地场景很多，另一方面也是因为这个岗位与我目前的学习方向非常契合。

所以我对这次面试其实是做了充分准备的，也很希望有机会加入并学习成长。

### 如果录用了你，将怎么展开工作

如果有幸被录用，我会尽快投入到工作中。首先，我会花时间熟悉公司整体的大数据平台架构、开发流程、代码规范以及数据中台的主要功能，确保自己能尽快跟上团队节奏。

同时，我会重点学习项目中用到的关键技术栈，比如 Java 后端框架、Kafka 的数据流转、Flink 的实时处理机制等，提升实战能力。

在具体任务中，我会从小模块做起，注重细节与规范，认真完成每一项工作内容，并虚心向同事请教，不断优化自己的工作方式。

此外，我也希望能逐渐参与到项目的测试、部署和优化过程中，不断提升全流程能力，力求在短时间内成为团队中值得信赖的一员。

### 空窗期

其实空窗期这段时间，我主要是边休息边充电。刚好前一段项目结束，我就想趁这个空档好好整理一下自己的知识体系。

这段时间我重点复习了 Java 基础，包括多线程、网络编程这些内容，也查漏补缺学了一些大数据方向的技术，比如看了 Hadoop、Spark 和 Flink 的视频课程，做了一些简单的实操练习。虽然是自学，但我觉得收获还是挺多的，尤其是对 Flink 的实时处理有了更直观的理解。

除了技术方面，我也花了时间优化简历，整理项目经历，平时也会看看大厂的一些面试题，算是给自己做准备吧。虽然暂时还没入职，但我一直保持积极状态，希望尽快进入工作节奏。

### 反问

请问实习期间是否会安排一位导师或带教人？如果我在项目中遇到困难，公司是否有比较成熟的沟通机制？
我想了解一下我所在的数据中台团队，成员之间的协作方式是怎样的？实习生是否有参与实际项目的机会？
对于数据中台方向的 Java 岗位，公司希望实习生在3个月或6个月后达到一个怎样的成长目标？
公司更看重实习生的一些什么品质，觉得什么样的实习生是自己想要的。



# 七、大模型LLM

大模型一般指参数规模在**数十亿到千亿**以上的深度学习模型，典型代表有：

GPT 系列（OpenAI）、文心一言、deepseek==>普遍使用**Transformer架构**，主要用于自然语言处理任务

### **训练流程**

训练大模型分为三个阶段：

1. **预训练（Pretraining）**：大规模无监督文本（如网络语料）训练语言理解与生成能力；
2. **指令微调（Instruction Tuning）**：使用人工标注数据做监督学习，使模型更好地遵循人类指令；
3. **强化学习微调（RLHF）**：用人类反馈训练策略模型，提升输出质量和安全性。

### 有哪些缺点或挑战？

**参考答案：**

- 幻觉（生成不真实内容）
- 对齐性差（不能理解复杂指令）
- 成本高（训练和部署都很贵）
- 隐私与数据安全问题

### 如果你要在后端系统中接入一个大模型API，关键的设计点有哪些？

**参考答案：**

1. **异步处理**：推理延迟大，建议使用消息队列或异步任务；
2. **缓存机制**：缓存常用问题答案或 embedding 结果，降低调用频率；
3. **限流和熔断**：保护大模型服务，防止过载；
4. **模型网关设计**：支持多模型、多租户、模型路由；
5. **安全策略**：输入输出做过滤，防止敏感信息泄露。

------

### 大模型与 RAG 的区别和联系？

**参考答案：**

- RAG（Retrieval-Augmented Generation）是在大模型生成之前，先通过检索系统拿到相关知识，再让模型进行生成；
- 能显著提升模型的准确性和实时性，常用于企业知识问答；
- Java后端可用**Elasticsearch + LLM + 向量库（如Faiss）**实现。

